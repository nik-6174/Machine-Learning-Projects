{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validating a Linear Regression Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_sample = self.data[idx, :]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\n",
    "            \"x\": torch.tensor(current_sample, dtype=torch.float),\n",
    "            \"y\": torch.tensor(current_target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification data from sklearn datasets\n",
    "data, targets = make_classification(n_samples=1000)\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(\n",
    "    data, \n",
    "    targets, \n",
    "    stratify=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LinearRegressionDataset(train_data, train_targets)\n",
    "test_dataset = LinearRegressionDataset(test_data, test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = lambda x, w, b: torch.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(20, 1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t Loss: 21.627449687808117\n",
      "Epoch 1 \t Loss: 7.610697101246803\n",
      "Epoch 2 \t Loss: 3.330258601681983\n",
      "Epoch 3 \t Loss: 1.5504278341268605\n",
      "Epoch 4 \t Loss: 0.7634357835384126\n",
      "Epoch 5 \t Loss: 0.4071569365568142\n",
      "Epoch 6 \t Loss: 0.24314670641460714\n",
      "Epoch 7 \t Loss: 0.1665539096017923\n",
      "Epoch 8 \t Loss: 0.13031198887124737\n",
      "Epoch 9 \t Loss: 0.11294939030104867\n",
      "Epoch 10 \t Loss: 0.10453257885169574\n",
      "Epoch 11 \t Loss: 0.10040629567935112\n",
      "Epoch 12 \t Loss: 0.09836203621779667\n",
      "Epoch 13 \t Loss: 0.09733950343240608\n",
      "Epoch 14 \t Loss: 0.09682374483499517\n",
      "Epoch 15 \t Loss: 0.09656184586012696\n",
      "Epoch 16 \t Loss: 0.09642826302591315\n",
      "Epoch 17 \t Loss: 0.0963600208546887\n",
      "Epoch 18 \t Loss: 0.09632525010594226\n",
      "Epoch 19 \t Loss: 0.09630766951731663\n",
      "Epoch 20 \t Loss: 0.09629895197886458\n",
      "Epoch 21 \t Loss: 0.0962947747989637\n",
      "Epoch 22 \t Loss: 0.09629289332673231\n",
      "Epoch 23 \t Loss: 0.09629216769145445\n",
      "Epoch 24 \t Loss: 0.09629198676222896\n",
      "Epoch 25 \t Loss: 0.09629205060984067\n",
      "Epoch 26 \t Loss: 0.09629222313734762\n",
      "Epoch 27 \t Loss: 0.09629240463131127\n",
      "Epoch 28 \t Loss: 0.0962925795143708\n",
      "Epoch 29 \t Loss: 0.09629272871422878\n",
      "Epoch 30 \t Loss: 0.09629286024248862\n",
      "Epoch 31 \t Loss: 0.09629295874595087\n",
      "Epoch 32 \t Loss: 0.0962930334362875\n",
      "Epoch 33 \t Loss: 0.0962931001459823\n",
      "Epoch 34 \t Loss: 0.09629315116809324\n",
      "Epoch 35 \t Loss: 0.09629318858199615\n",
      "Epoch 36 \t Loss: 0.09629321934536417\n",
      "Epoch 37 \t Loss: 0.0962932415881214\n",
      "Epoch 38 \t Loss: 0.0962932546501682\n",
      "Epoch 39 \t Loss: 0.09629325847081999\n",
      "Epoch 40 \t Loss: 0.09629326927639108\n",
      "Epoch 41 \t Loss: 0.09629328457757513\n",
      "Epoch 42 \t Loss: 0.09629329447040057\n",
      "Epoch 43 \t Loss: 0.09629329643336106\n",
      "Epoch 44 \t Loss: 0.09629329747862202\n",
      "Epoch 45 \t Loss: 0.09629330348144187\n",
      "Epoch 46 \t Loss: 0.09629330278418839\n",
      "Epoch 47 \t Loss: 0.09629330220335025\n",
      "Epoch 48 \t Loss: 0.09629330366225715\n",
      "Epoch 49 \t Loss: 0.09629330608840199\n",
      "Epoch 50 \t Loss: 0.09629330801792403\n",
      "Epoch 51 \t Loss: 0.09629330343066497\n",
      "Epoch 52 \t Loss: 0.09629330673859396\n",
      "Epoch 53 \t Loss: 0.09629330691569386\n",
      "Epoch 54 \t Loss: 0.09629330781977029\n",
      "Epoch 55 \t Loss: 0.09629330798572405\n",
      "Epoch 56 \t Loss: 0.09629331053571498\n",
      "Epoch 57 \t Loss: 0.0962933068129016\n",
      "Epoch 58 \t Loss: 0.09629330931706949\n",
      "Epoch 59 \t Loss: 0.0962933075696012\n",
      "Epoch 60 \t Loss: 0.0962933063224711\n",
      "Epoch 61 \t Loss: 0.09629330639058645\n",
      "Epoch 62 \t Loss: 0.09629330831763157\n",
      "Epoch 63 \t Loss: 0.09629330913253882\n",
      "Epoch 64 \t Loss: 0.09629330639801721\n",
      "Epoch 65 \t Loss: 0.09629330758817811\n",
      "Epoch 66 \t Loss: 0.09629330671630165\n",
      "Epoch 67 \t Loss: 0.09629330916969264\n",
      "Epoch 68 \t Loss: 0.09629330627788651\n",
      "Epoch 69 \t Loss: 0.09629330674107088\n",
      "Epoch 70 \t Loss: 0.0962933061577558\n",
      "Epoch 71 \t Loss: 0.09629330705068609\n",
      "Epoch 72 \t Loss: 0.09629330691693232\n",
      "Epoch 73 \t Loss: 0.09629330647356332\n",
      "Epoch 74 \t Loss: 0.09629330779623954\n",
      "Epoch 75 \t Loss: 0.09629330715100143\n",
      "Epoch 76 \t Loss: 0.09629330742841666\n",
      "Epoch 77 \t Loss: 0.09629330709279377\n",
      "Epoch 78 \t Loss: 0.09629330798943943\n",
      "Epoch 79 \t Loss: 0.09629330494282569\n",
      "Epoch 80 \t Loss: 0.09629330707669377\n",
      "Epoch 81 \t Loss: 0.0962933070630707\n",
      "Epoch 82 \t Loss: 0.09629330742965511\n",
      "Epoch 83 \t Loss: 0.09629330562893301\n",
      "Epoch 84 \t Loss: 0.09629330513354867\n",
      "Epoch 85 \t Loss: 0.09629330523881784\n",
      "Epoch 86 \t Loss: 0.09629330625807113\n",
      "Epoch 87 \t Loss: 0.09629330793123177\n",
      "Epoch 88 \t Loss: 0.09629330690083232\n",
      "Epoch 89 \t Loss: 0.09629330700981688\n",
      "Epoch 90 \t Loss: 0.09629330570076375\n",
      "Epoch 91 \t Loss: 0.09629330677450931\n",
      "Epoch 92 \t Loss: 0.09629330694789384\n",
      "Epoch 93 \t Loss: 0.0962933070345861\n",
      "Epoch 94 \t Loss: 0.09629330720301678\n",
      "Epoch 95 \t Loss: 0.09629330552861769\n",
      "Epoch 96 \t Loss: 0.09629330722530907\n",
      "Epoch 97 \t Loss: 0.09629330788788563\n",
      "Epoch 98 \t Loss: 0.09629330756217043\n",
      "Epoch 99 \t Loss: 0.09629330705440148\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    counter = 0\n",
    "    for data in train_loader:\n",
    "        xtrain, ytrain = data[\"x\"], data['y']\n",
    "\n",
    "        output = model(xtrain, W, b)\n",
    "        loss = torch.mean((output.view(-1) - ytrain.view(-1)) ** 2)\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            W = W - learning_rate * W.grad\n",
    "            b = b - learning_rate * b.grad\n",
    "        \n",
    "        W.requires_grad_(True)\n",
    "        b.requires_grad_(True)\n",
    "        counter += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch} \\t Loss: {epoch_loss/counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        xtest, ytest = data[\"x\"], data[\"y\"]\n",
    "\n",
    "        output = model(xtest, W, b)\n",
    "        labels.append(ytest)\n",
    "        outputs.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968192"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model performance\n",
    "metrics.roc_auc_score(torch.cat(labels).view(-1), torch.cat(outputs).view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(model, data, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    for k, v in data.items():\n",
    "        data[k] = v.to(\"cuda\")\n",
    "    loss = model(**data)\n",
    "    # loss = model(data[\"x\"], data[\"y\"])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_index, data in enumerate(data_loader):\n",
    "        loss = train_one_step(model, data, optimizer)\n",
    "        scheduler.step()\n",
    "        total_loss += loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_step(model, data):\n",
    "    for k, v in data.items():\n",
    "        data[k] = v.to(\"cuda\")\n",
    "    loss = model(**data)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch_index, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = validate_one_step(model, data)\n",
    "        total_loss += loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
